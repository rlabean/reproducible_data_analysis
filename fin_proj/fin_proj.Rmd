---
title: "Geoscience Salary Survey"
output: html_notebook
author: Robert LaBean
---

```{r echo=FALSE}

library(tidyverse)
library(readxl)
library(rvest)

```

Accessing the Bureau of Labor Statistics most current state salary data.

```{r}

url <- "https://www.bls.gov/oes/special.requests/oesm19st.zip"

temp <- tempfile()
temp2 <- tempfile()

download.file(url, temp)
unzip(zipfile = temp, exdir = temp2)
raw_salary_data <- read_excel(file.path(temp2, "oesm19st/state_M2019_dl.xlsx"))

unlink(c(temp, temp2))

```

Next, we're going to scrape the Missouri Economic Research and Information Center (MERIC) web page an use their calculation for a cost of living index. I like this calculation because they take the cost of living index for each city in a state and average it to make a state cost of living index.

```{r}

scrape_url <- "https://meric.mo.gov/data/cost-living-data-series"
webpage <- read_html(scrape_url)
web_tables <- html_nodes(webpage, "table")
state_list <- html_table(web_tables)[[1]]

glimpse(state_list)

```

Now, I'm combining both data-sets into one. I'm also cleaning the data a bit as we aren't going to be needing a lot of the information from the MERIC data-set

```{r}

col_index <- filter(state_list, !grepl("District of Columbia|Puerto Rico|US", State)) %>%
  arrange(State)
salary_data <- inner_join(raw_salary_data, col_index, by = c("area_title" = "State"))


glimpse(col_index)

```

Finally we're going to normalize all the salaries with our cost of living index and plot it on a chart to see which states typically have the highest salaries compared to their respective cost of living. 

```{r}

salary_data$normalized = as.numeric(salary_data$a_mean) / (salary_data$Index/100)

plot_sal_data <- function(x, y){
 
salary_plot <- ggplot(salary_data) +
  theme(axis.text.x = element_text(angle = 45))+
    geom_col(mapping = aes(x, y))
  
print(salary_plot)
    }

plot_sal_data(area_title, a_mean)


```